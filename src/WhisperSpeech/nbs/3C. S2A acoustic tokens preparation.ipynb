{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7fdbe3b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| default_exp prepare_s2a_atoks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cf56fcb",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ecbdddfd",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| export\n",
                "import sys\n",
                "import os\n",
                "import itertools\n",
                "from pathlib import Path\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "\n",
                "from fastprogress import progress_bar\n",
                "from fastcore.script import *\n",
                "\n",
                "import webdataset as wds\n",
                "from WhisperSpeech.whisperspeech import utils, vad_merge\n",
                "from WhisperSpeech.whisperspeech.inference import get_compute_device"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e1d80d3b",
            "metadata": {},
            "source": [
                "# S2A dataset preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e1a5312",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "def load_model():\n",
                "    \"Load the pretrained EnCodec model\"\n",
                "    from encodec.model import EncodecModel\n",
                "    model = EncodecModel.encodec_model_24khz()\n",
                "    model.set_target_bandwidth(1.5)\n",
                "    model.to(get_compute_device()).eval()\n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f271d55",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "@call_parse\n",
                "def prepare_atoks(\n",
                "    input:str,  # audio file webdataset file path\n",
                "    output:str, # output shard path\n",
                "    n_samples:int=None, # process a limited amount of samples\n",
                "    batch_size:int=4, # process several segments at once\n",
                "    bandwidth:float=3,\n",
                "):\n",
                "    device = get_compute_device()\n",
                "    amodel = load_model().to(device)  # Move model to computed device\n",
                "    amodel.set_target_bandwidth(bandwidth)\n",
                "\n",
                "    total = n_samples//batch_size if n_samples else 'noinfer'\n",
                "    if n_samples: print(f\"Benchmarking run of {n_samples} samples ({total} batches)\")\n",
                "\n",
                "    if total == 'noinfer':\n",
                "        import math, time\n",
                "        start = time.time()\n",
                "        ds = wds.WebDataset([utils.derived_name(input, 'mvad')]).decode()\n",
                "        total = math.ceil(sum([len(x['max.spk_emb.npy']) for x in ds])/batch_size)\n",
                "        print(f\"Counting {total} batches: {time.time()-start:.2f}\")\n",
                "\n",
                "    ds = vad_merge.chunked_audio_dataset([input], 'max').compose(\n",
                "        utils.resampler(24000, 'samples_24k'),\n",
                "        wds.to_tuple('__key__', 'rpad_s', 'samples_24k'),\n",
                "        wds.batched(64),\n",
                "    )\n",
                "\n",
                "    dl = wds.WebLoader(ds, num_workers=1, batch_size=None).unbatched().batched(batch_size)\n",
                "\n",
                "    with utils.AtomicTarWriter(output, throwaway=n_samples is not None) as sink:\n",
                "        for keys, rpad_ss, samples in progress_bar(dl, total=total):\n",
                "            csamples = samples.to(device).unsqueeze(1)  # Move tensors to computed device\n",
                "            atokss = amodel.encode(csamples)[0][0]\n",
                "            atokss = atokss.cpu().numpy().astype(np.int16)\n",
                "            for key, rpad_s, atoks in zip(keys, rpad_ss, atokss):\n",
                "                atoks = atoks[:,:int((30-rpad_s) * 75 + 0.5)]\n",
                "                sink.write({\n",
                "                    \"__key__\": key,\n",
                "                    \"atoks.npy\": atoks,\n",
                "                })"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
