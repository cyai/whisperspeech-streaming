{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fe7942",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb5afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| default_exp benchmark\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93525c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import time\n",
    "import torch\n",
    "from fastcore.script import call_parse\n",
    "from whisperspeech.pipeline import Pipeline\n",
    "from whisperspeech.inference import get_compute_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be72e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "#| exporti\n",
    "def measure(fun, iterations = 10):\n",
    "    ts = []\n",
    "    for x in range(iterations):\n",
    "        start = time.time()\n",
    "        fun()\n",
    "        getattr(torch, get_compute_device()).synchronize()\n",
    "        ts.append(time.time() - start)\n",
    "    ts = torch.tensor(ts)\n",
    "    return ts.mean(), ts.std()\n",
    "\n",
    "@call_parse\n",
    "def benchmark(\n",
    "    t2s_ref='collabora/whisperspeech:t2s-small-en+pl.model',\n",
    "    s2a_ref='collabora/whisperspeech:s2a-q4-tiny-en+pl.model',\n",
    "    batch_size : int = 1,\n",
    "    max_batch_size : int = None,\n",
    "    no_torch_compile : bool = False,\n",
    "    s2a_ctx_n : int = None,\n",
    "    t2s_ctx_n : int = None,\n",
    "    iterations = 10,\n",
    "):\n",
    "    max_batch_size = max_batch_size or batch_size\n",
    "\n",
    "    pipe = Pipeline(t2s_ref=t2s_ref, s2a_ref=s2a_ref, optimize=False)\n",
    "\n",
    "    if t2s_ctx_n:\n",
    "        pipe.t2s.stoks_len = t2s_ctx_n\n",
    "        pipe.t2s.decoder.mask = torch.empty(t2s_ctx_n, t2s_ctx_n).fill_(-torch.inf).triu_(1).to(get_compute_device())\n",
    "    \n",
    "    pipe.t2s.optimize(max_batch_size=max_batch_size, torch_compile=not no_torch_compile)\n",
    "\n",
    "    if s2a_ctx_n:\n",
    "        pipe.s2a.ctx_n = s2a_ctx_n\n",
    "        pipe.s2a.decoder.mask = torch.empty(s2a_ctx_n, s2a_ctx_n).fill_(-torch.inf).triu_(1).to(get_compute_device())\n",
    "\n",
    "    pipe.s2a.optimize(max_batch_size=max_batch_size, torch_compile=not no_torch_compile)\n",
    "\n",
    "    txt = \"This is the first demo of Whisper Speech, a fully open source text-to-speech model trained by Collabora and Lion on the Juwels supercomputer.\"\n",
    "    stoks = torch.zeros(250)\n",
    "    t = len(stoks)/25\n",
    "    \n",
    "    def t2s():\n",
    "        return pipe.t2s.generate(txt, bs=batch_size, show_progress_bar=False)\n",
    "    def s2a():\n",
    "        return pipe.s2a.generate(stoks, pipe.default_speaker.unsqueeze(0), bs=batch_size, show_progress_bar=False)\n",
    "\n",
    "    # warmup\n",
    "    t2s()\n",
    "    s2a()\n",
    "    \n",
    "    t2s_mean, t2s_std = measure(t2s, iterations=iterations)\n",
    "    s2a_mean, s2a_std = measure(s2a, iterations=iterations)\n",
    "    print(f\"T2S: {t2s_mean:.3f} ± {t2s_std:.3f} s    S2A: {s2a_mean:.3f} ± {s2a_std:.3f} s    Total: {t2s_mean+s2a_mean:.3f} s\")\n",
    "    print(f\"     {t/t2s_mean:.2f}x                  {t/s2a_mean:.2f}x                    {t/(t2s_mean+s2a_mean):.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
