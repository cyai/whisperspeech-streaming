{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b938bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp split_out_val_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import os\n",
    "import webdataset as wds\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.script import call_parse\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from whisperspeech import utils, vad_merge\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c56443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@call_parse\n",
    "def split_dataset(\n",
    "    shard_dir:str,\n",
    "    splits:str,\n",
    "    mvad_kind:str=None,\n",
    "):\n",
    "    mode = Path(shard_dir).name\n",
    "\n",
    "    if mode == \"audio\":\n",
    "        shards = utils.shard_glob(shard_dir+'/*.tar')\n",
    "    else:\n",
    "        shards = utils.shard_glob(shard_dir+'/*.tar.gz')\n",
    "\n",
    "    splits = splits.split()\n",
    "\n",
    "    # unpacks sample id 'src_key_001' into 'src_key', '001'\n",
    "    def unpack_id(x):\n",
    "        return x.rsplit('_', 1)\n",
    "\n",
    "    def make_tar_writer(name):\n",
    "        name.parent.mkdir(parents=True, exist_ok=True)\n",
    "        return wds.TarWriter(str(name))\n",
    "    \n",
    "    suffix = \".tar.gz\" if mode != 'audio' else \".tar\"\n",
    "    \n",
    "    bufs = {k:[] for k in splits}\n",
    "    outputs = {k:make_tar_writer(Path(k).parent/mode/(Path(k).name+suffix)) for k in splits}\n",
    "\n",
    "    if mode == \"audio\" or mode == \"mvad\":\n",
    "        needles = {}\n",
    "        chunks = defaultdict(lambda: [])\n",
    "        for split in splits:\n",
    "            for k in utils.readlines(split):\n",
    "                file_id, chunk_id = unpack_id(k)\n",
    "                needles[file_id] = bufs[split]\n",
    "                chunks[file_id].append(int(chunk_id))\n",
    "    else:\n",
    "        needles = {k:bufs[split] for split in splits for k in utils.readlines(split)}\n",
    "        chunks = None\n",
    "\n",
    "    print(f\"Generating splits: {' '.join(outputs.keys())}, looking for {len(needles)} {mode} samples...\")\n",
    "    \n",
    "    ds = wds.WebDataset(shards).compose(\n",
    "        wds.select(lambda x: x['__key__'] in needles),\n",
    "    )\n",
    "    if mode == 'mvad': ds = ds.decode()\n",
    "    \n",
    "    dl = wds.WebLoader(ds, num_workers=0 if len(shards) > 10 else 16, batch_size=None)\n",
    "\n",
    "    for s in progress_bar(dl, total='noinfer'):\n",
    "        if mode == \"mvad\":\n",
    "            mask = np.zeros(s[mvad_kind+'.vad.npy'].shape[0], dtype=np.bool_)\n",
    "            for i in chunks[s['__key__']]: mask[i] = True\n",
    "            new = {}\n",
    "            for k in ['__key__', mvad_kind+'.vad.npy', mvad_kind+'.spk_emb.npy', mvad_kind+'.subvads.pyd', 'gain_shift.npy']:\n",
    "                v = s[k]\n",
    "                if isinstance(v, torch.Tensor): v = v.numpy()\n",
    "                new[k] = v\n",
    "            new['mask.npy'] = mask\n",
    "            s = new\n",
    "        needles[s['__key__']].append(copy.deepcopy(s))\n",
    "        del needles[s['__key__']]\n",
    "        pass\n",
    "    print()\n",
    "\n",
    "    for split,buf in bufs.items():\n",
    "        for s in sorted(buf, key=lambda x: x['__key__']):\n",
    "            outputs[split].write(s)\n",
    "    \n",
    "    if len(needles) > 0:\n",
    "        print(f\"Missed {len(needles)} samples!\")\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
