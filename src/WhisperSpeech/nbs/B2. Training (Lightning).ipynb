{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2afd7255",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| default_exp train_multi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12e79ccb",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| hide\n",
                "from nbdev.showdoc import *"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7dfd417d",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "import io\n",
                "import os\n",
                "import time\n",
                "import random\n",
                "import re\n",
                "from pathlib import Path\n",
                "import requests\n",
                "\n",
                "from fastprogress import progress_bar, master_bar\n",
                "import fastprogress\n",
                "import wandb\n",
                "\n",
                "import numpy as np\n",
                "import pylab as plt\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data.dataloader import DataLoader\n",
                "from torch.profiler import record_function\n",
                "from WhisperSpeech.whisperspeech import utils, testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "232153f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "import lightning.pytorch as pl\n",
                "import math\n",
                "\n",
                "class TrainingTask(pl.LightningModule):\n",
                "    def __init__(self, model, model_hparams=None):\n",
                "        super().__init__()\n",
                "        self.model = model\n",
                "        self.model_hparams = model_hparams\n",
                "        \n",
                "    def on_fit_start(self):\n",
                "        if getattr(self.model, 'setup'):\n",
                "            self.model.setup(self.device)\n",
                "        if self.model_hparams['torch_compile'] and getattr(self.model, 'optimize_training'):\n",
                "            import torch._dynamo\n",
                "            torch._dynamo.config.optimize_ddp = False\n",
                "            # FIXME: define a batch of dummy tensors in the model\n",
                "            testing.test_model(model, train_dss[0], bs=batch_size)\n",
                "            model.optimize_training()\n",
                "    \n",
                "    def configure_optimizers(self):\n",
                "        \"\"\" Initialize AdamW optimizer\"\"\"\n",
                "        lr = self.model_hparams['lr0']\n",
                "        weight_decay = self.model_hparams['weight_decay']\n",
                "        \n",
                "        all_params = set(model.parameters())\n",
                "        customized_params = set()\n",
                "        groups = []\n",
                "        group_map = {}\n",
                "        for name,m in model.named_modules():\n",
                "            if hasattr(m, 'no_weight_decay') or hasattr(m, 'lr_scale'):\n",
                "                customized_params |= set(m.parameters())\n",
                "                m_wd = 0 if hasattr(m, 'no_weight_decay') else weight_decay\n",
                "                m_lr = lr * getattr(m, 'lr_scale', 1)\n",
                "                group = group_map.get((m_wd, m_lr), None)\n",
                "                if not group:\n",
                "                    group = {\"params\": [], \"names\": [], \"weight_decay\": m_wd, \"lr\": m_lr}\n",
                "                    groups.append(group)\n",
                "                    group_map[(m_wd, m_lr)] = group\n",
                "                group['params'] += m.parameters()\n",
                "                group['names'].append(name)\n",
                "                \n",
                "        other_params = all_params - customized_params\n",
                "        \n",
                "        param_groups = groups + [\n",
                "            {\"names\": [\"other\"], \"params\": list(other_params), \"weight_decay\": weight_decay },\n",
                "        ]\n",
                "\n",
                "        optimizer = torch.optim.AdamW(lr=lr, betas=(0.9, 0.95), params=param_groups)\n",
                "        \n",
                "        # modified from https://github.com/Lightning-AI/lightning/issues/5449#issuecomment-1501597319\n",
                "        def num_steps_per_epoch() -> int:\n",
                "            \"\"\"Get number of steps\"\"\"\n",
                "            # Accessing _data_source is flaky and might break\n",
                "            dataset = self.trainer.fit_loop._data_source.dataloader()\n",
                "            dataset_size = len(dataset)\n",
                "            # math.ceil so always overestimate (underestimating throws exceptions)\n",
                "            num_steps = math.ceil(dataset_size / self.trainer.accumulate_grad_batches)\n",
                "            return num_steps\n",
                "        \n",
                "        warmup_steps = self.model_hparams['warmup_steps']\n",
                "        total_steps = self.model_hparams['iterations']\n",
                "        self.model_hparams['pct_start'] = min(0.3, warmup_steps / total_steps)\n",
                "\n",
                "        print(f\"{self.model_hparams['iterations']=} steps\")\n",
                "\n",
                "        if self.model_hparams['lr_schedule'] == 'cosine':\n",
                "            lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
                "                optimizer,\n",
                "                pct_start=self.model_hparams['pct_start'],\n",
                "                max_lr=[pg.get('lr', lr) for pg in param_groups],\n",
                "                steps_per_epoch=num_steps_per_epoch(),\n",
                "                epochs=1,\n",
                "                final_div_factor=25\n",
                "            )\n",
                "        elif self.model_hparams['lr_schedule'] == 'linear':\n",
                "            warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
                "                optimizer, 1e-3, 1, warmup_steps\n",
                "            )\n",
                "            train_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
                "                optimizer, 1, 1/25, total_steps - warmup_steps\n",
                "            )\n",
                "            lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
                "                optimizer, schedulers=[warmup_scheduler, train_scheduler], milestones=[warmup_steps]\n",
                "            )\n",
                "        elif self.model_hparams['lr_schedule'] == 'wsd':\n",
                "            warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
                "                optimizer, 1e-3, 1, warmup_steps\n",
                "            )\n",
                "            train_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
                "                optimizer, [int(total_steps - warmup_steps - 0.1*total_steps)], 1/8,\n",
                "            )\n",
                "            lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
                "                optimizer, schedulers=[warmup_scheduler, train_scheduler], milestones=[warmup_steps]\n",
                "            )\n",
                "        else:\n",
                "            raise Exception(\"Unknown learning rate schedule\")\n",
                "\n",
                "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
                "    \n",
                "    def training_step(self, train_batch, batch_idx):\n",
                "        train_out = self.model.forward(*train_batch)\n",
                "        train_loss = train_out[-1]\n",
                "\n",
                "        self.log(\"train_loss\", train_loss, sync_dist=True)\n",
                "        return train_loss\n",
                "    \n",
                "    def validation_step(self, val_batch, batch_idx, dataloader_idx=0):\n",
                "        val_out = self.model.forward(*val_batch)\n",
                "        val_loss = val_out[-1]\n",
                "\n",
                "        name = val_dss_names[dataloader_idx]\n",
                "        self.log(f\"val_loss/{name}\", val_loss.detach(), sync_dist=True, add_dataloader_idx=False)\n",
                "        if hasattr(self.model, 'get_metrics'):\n",
                "            self.log_dict({f'metrics/{k}_{name}':v for k,v in self.model.get_metrics().items()}, sync_dist=True, add_dataloader_idx=False)\n",
                "        return val_loss.detach()\n",
                "    \n",
                "    def on_validation_epoch_end(self):\n",
                "        for name, weight in zip(train_dss_names, train_weights):\n",
                "            self.log(f\"trainer/{name}-batches\", weight.to(self.device) * self.global_step, sync_dist=True)\n",
                "    \n",
                "    def test_step(self, val_batch, batch_idx):\n",
                "        test_out = self.model.forward(*val_batch)\n",
                "        test_loss = test_out[-1]\n",
                "\n",
                "        self.log(\"test_loss\", test_loss, sync_dist=True)\n",
                "        return test_loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae232d52",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "from fastcore.script import anno_parser\n",
                "import shlex\n",
                "\n",
                "# watch out: we can only pass Python values as keyword arguments (not positional)\n",
                "# everything else has to be a string\n",
                "def parse_and_call(name, fun, args, kwargs={}, log_to_wandb=True):\n",
                "    print(f\"Parsing arguments for {name}, {args}\")\n",
                "    p = anno_parser(fun, prog=name)\n",
                "    args = p.parse_args(args).__dict__\n",
                "    args.pop('xtra'); args.pop('pdb')\n",
                "    args.update({k:v for k, v in kwargs.items()})\n",
                "    if log_to_wandb and type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
                "        wandb_logger.experiment.config[name] = {k:v for k,v in args.items() if k not in ['dataset', 'tunables']}\n",
                "    return fun(**args)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b23790e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[] 4 False\n"
                    ]
                }
            ],
            "source": [
                "def test_fun(a:str=None, to:int = 2, toggle:bool=True):\n",
                "    assert(a is not None)\n",
                "    print(a, to, toggle)\n",
                "parse_and_call(\"test\", test_fun, [\"--to\", \"4\"], dict(a=[]), log_to_wandb=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1d8ac45a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "a 2 True\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "Namespace(a=None, to=2, toggle=False, pdb=False, xtra=None)"
                        ]
                    },
                    "execution_count": null,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from fastcore.script import anno_parser\n",
                "def test_fun(a:str=None, to:int = 2, toggle:bool=True):\n",
                "    assert(a is not None)\n",
                "    print(a, to, toggle)\n",
                "test_fun(\"a\")\n",
                "anno_parser(test_fun).parse_args([])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bd039c0a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "qwe 2\n"
                    ]
                }
            ],
            "source": [
                "def test_fun2(a:str, to:int = 2):\n",
                "    assert(a is not None)\n",
                "    print(a, to)\n",
                "\n",
                "parse_and_call(\"test\", test_fun2, [\"qwe\"], log_to_wandb=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e7ec1a6",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "# split only full path components to stabilize the names\n",
                "def simplify_folder_names(lst):\n",
                "    lst = [x.strip('/') for x in lst] # normalize pathnames, removing trailing and leading slashes\n",
                "    parts = [x.split('/') for x in lst]\n",
                "    prefix = os.path.commonprefix(parts)\n",
                "    suffix = os.path.commonprefix([x[::-1] for x in parts])\n",
                "    print(prefix, suffix)\n",
                "    return ['_'.join(x[len(prefix):len(x)-len(suffix)]) for x in parts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a9474199",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['youtube-cc', 'mls-spanish']"
                        ]
                    },
                    "execution_count": null,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# strip path suffixes (useful for validation splits)\n",
                "simplify_folder_names(['/data2/youtube-cc/txt-random-valid', '/data2/mls-spanish/txt-random-valid'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1c3dd26f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['mls-spanish', 'mls-polish']"
                        ]
                    },
                    "execution_count": null,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# strip path prefixes but only full folders\n",
                "simplify_folder_names(['/data2/mls-spanish', '/data2/mls-polish'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7822542c",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "import argparse\n",
                "\n",
                "parser = argparse.ArgumentParser()\n",
                "parser.add_argument('--task', type=str, help='Task to train')\n",
                "parser.add_argument('--seed', type=int, default=0, help='Global training seed')\n",
                "parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
                "parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')\n",
                "parser.add_argument('--input-dir', type=str, default='', help='input data path') # fixed in the model for now\n",
                "parser.add_argument('--dataset-config', type=str, default='', help='common dataset options')\n",
                "parser.add_argument('--training-data', action='append', type=str, default=[], help='training dataset')\n",
                "parser.add_argument('--validation-data', action='append', type=str, default=[], help='validation dataset (can be passed multiple times)')\n",
                "parser.add_argument('--monitored-metric', type=str, default=\"val_loss\", help='metric to monitor for checkpointing')\n",
                "parser.add_argument(\"--checkpoint-dir\", type=str, default=\"./checkpoints/\", help=\"directory to save the checkpoints\")\n",
                "parser.add_argument('--iterations', type=int, default=8000, help='total training iterations')\n",
                "parser.add_argument('--validate-every-n-steps', type=int, default=500, help='how training steps to run between validations')\n",
                "parser.add_argument('--weight-decay', type=float, default=1e-2, help='optimizer weight decay')\n",
                "parser.add_argument('--lr0', type=float, default=1e-4, help='optimizer initial learning rate')\n",
                "parser.add_argument('--lr-schedule', type=str, default=\"cosine\", help='the learning rate schedule [cosine, linear or wsd]')\n",
                "parser.add_argument('--clip-gradient-norm', type=float, default=None, help='enable gradient norm clipping')\n",
                "parser.add_argument('--accumulate-grad-batches', type=int, default=1, help='perform the optimizer step only after going through several batches of samples')\n",
                "parser.add_argument('--precision', type=str, default=\"16-mixed\", help=\"floating point precision\")\n",
                "parser.add_argument('--torch-compile', type=bool, default=False, help='compile (parts of) the model with torch.compile')\n",
                "parser.add_argument('--warmup-steps', type=int, default=10000, help='total number steps during which the learning rate rises (defaults to 10k updates)')\n",
                "parser.add_argument('--tunables', type=str, default=\"\", help='tunable hyperparameters')\n",
                "parser.add_argument('--resume-from', type=Path, default=None, help='resume training from the given checkpoint')\n",
                "parser.add_argument('--load-from', type=Path, default=None, help='initialize the weights from the given model')\n",
                "parser.add_argument('--strategy', type=str, default='ddp', help='distributed training strategy')\n",
                "parser.add_argument('--wandb-suffix', type=str, default=None, help='W&B project name suffix')\n",
                "parser.add_argument('--wandb-task-name', type=str, default=None, help='Task name for the W&B project name')\n",
                "\n",
                "args = parser.parse_args().__dict__\n",
                "\n",
                "task_args: list = shlex.split(args.pop(\"task\"))\n",
                "task_name, task_args = task_args[0], task_args[1:]\n",
                "input_args: list = shlex.split(args.pop(\"input_dir\"))\n",
                "dataset_config: list = shlex.split(args.pop(\"dataset_config\"))\n",
                "monitored_metric: str = args.pop(\"monitored_metric\")\n",
                "checkpoint_dir: str = args.pop(\"checkpoint_dir\")\n",
                "num_workers: int = args.pop(\"workers\")\n",
                "batch_size: int = args.pop(\"batch_size\")\n",
                "iterations: int = args.pop(\"iterations\")\n",
                "tunables_args: list = shlex.split(args.pop(\"tunables\"))\n",
                "\n",
                "hyp_params = {}\n",
                "hyp_params['batch_size'] = batch_size\n",
                "hyp_params['warmup_steps'] = args['warmup_steps']\n",
                "hyp_params['weight_decay'] = args['weight_decay']\n",
                "hyp_params['clip_gradient_norm'] = args['clip_gradient_norm']\n",
                "hyp_params['accumulate_grad_batches'] = args['accumulate_grad_batches']\n",
                "hyp_params['validate_every_n_steps'] = args[\"validate_every_n_steps\"]\n",
                "hyp_params['precision'] = args['precision']\n",
                "hyp_params['torch_compile'] = args['torch_compile']\n",
                "hyp_params['lr0'] = args['lr0']\n",
                "hyp_params['lr_schedule'] = args['lr_schedule']\n",
                "hyp_params['iterations'] = iterations\n",
                "hyp_params['strategy'] = args['strategy']\n",
                "if 'SLURM_NTASKS' in os.environ:\n",
                "    hyp_params['world_size'] = os.environ['SLURM_NTASKS']\n",
                "else:\n",
                "    hyp_params['world_size'] = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "38e8af5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "def parse_dataset_string(s):\n",
                "    cwd = [None]\n",
                "    def load_file_reference(matchobj):\n",
                "        fname = matchobj.group(1)\n",
                "        cwd[0] = Path(fname).parent\n",
                "        if fname.startswith('http://') or fname.startswith('https://'):\n",
                "            response = requests.get(target_url)\n",
                "            return response.text.strip()\n",
                "        else:\n",
                "            with open(fname, 'r') as f:\n",
                "                return f.read().strip()\n",
                "    s = re.sub('@([^ ]+)', load_file_reference, s)\n",
                "    arg_list = shlex.split(s)\n",
                "    if cwd[0]: arg_list += ['--cwd', str(cwd[0])]\n",
                "    return arg_list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a224add7",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| exporti\n",
                "from lightning.pytorch.loggers import WandbLogger\n",
                "from lightning.pytorch.callbacks import LearningRateMonitor\n",
                "from lightning.fabric.utilities.rank_zero import rank_zero_only\n",
                "import datetime\n",
                "import webdataset as wds\n",
                "import importlib\n",
                "import dataclasses\n",
                "\n",
                "torch.set_float32_matmul_precision('medium')\n",
                "\n",
                "project = f\"WhisperSpeech-{args['wandb_task_name'] or task_name}\"\n",
                "if args['wandb_suffix']:\n",
                "    project += \"-\"+args['wandb_suffix']\n",
                "\n",
                "from faker import Faker\n",
                "fake = Faker()\n",
                "name = (fake.name().split()[0] + \"_\" + fake.color_name()).lower()\n",
                "\n",
                "if rank_zero_only.rank == 0:\n",
                "    print('Experiment name:', name)\n",
                "wandb_logger = WandbLogger(project=project, name=name)\n",
                "\n",
                "ckpt_callback = pl.callbacks.ModelCheckpoint(\n",
                "     dirpath=f'{task_name}',\n",
                "     filename=f'{task_name}-{name}'+\"-{step}-acc={\"+monitored_metric+\":.2f}\",\n",
                "     monitor=monitored_metric,\n",
                "     save_top_k=16,\n",
                "     train_time_interval=datetime.timedelta(minutes=14),\n",
                "     auto_insert_metric_name=False\n",
                ")\n",
                "\n",
                "lr_monitor_callback = LearningRateMonitor(logging_interval='step')\n",
                "\n",
                "task = importlib.import_module(\"whisperspeech.\"+task_name)\n",
                "\n",
                "# load all training sets\n",
                "train_dss = [parse_and_call(f'train_ds_{i}', task.load_dataset,\n",
                "                            parse_dataset_string(train_ds_config) + dataset_config)\n",
                "             for i,train_ds_config in enumerate(args['training_data'])]\n",
                "train_dss_names = simplify_folder_names([parse_dataset_string(train_ds_config)[0] for train_ds_config in args['training_data']])\n",
                "print('train names:', train_dss_names)\n",
                "counts = [x.total_samples for x in train_dss]\n",
                "print(counts)\n",
                "print(torch.tensor(counts).log2())\n",
                "train_weights = torch.tensor(counts).log2() - torch.tensor(counts).log2().min() + 1\n",
                "for tds, w in zip(train_dss, train_weights):\n",
                "    tds.weight = w\n",
                "\n",
                "train_total_batches = hyp_params['iterations']\n",
                "if train_total_batches < hyp_params['validate_every_n_steps']:\n",
                "    # validate once at the end of every epoch for very short experiments\n",
                "    hyp_params['validate_every_n_steps'] = train_total_batches\n",
                "\n",
                "# persistent_workers=True is critical here so we don't reset the sample shuffling buffers\n",
                "# with webdatasets sample shuffling is very bad initially, unless num_workers << num_shards\n",
                "train_loader = wds.WebLoader(\n",
                "    utils.join_datasets(train_dss),\n",
                "    num_workers=num_workers, drop_last=False, batch_size=None, shuffle=False, persistent_workers=num_workers > 0,\n",
                ").unbatched().shuffle(1024).batched(batch_size).with_length(train_total_batches)\n",
                "\n",
                "# load all validation sets\n",
                "val_dss_names = [parse_dataset_string(val_ds_config)[0] for val_ds_config in args['validation_data']]\n",
                "val_dss_names = simplify_folder_names(val_dss_names)\n",
                "print('validation names:', val_dss_names)\n",
                "\n",
                "val_dss = [parse_and_call(f'val_ds_{i}', task.load_dataset,\n",
                "                          parse_dataset_string(val_ds_config) + dataset_config, {'validation': True})\n",
                "           for i,val_ds_config in enumerate(args['validation_data'])]\n",
                "val_loaders = [wds.WebLoader(\n",
                "        val_ds, num_workers=num_workers, drop_last=False, batch_size=None, shuffle=False,\n",
                "    ).unbatched().batched(batch_size).with_length(val_ds.total_samples // batch_size)\n",
                "   for val_ds in val_dss]\n",
                "\n",
                "tunables = None\n",
                "if hasattr(task, \"Tunables\"):\n",
                "    tunables = parse_and_call('tunables', task.Tunables, tunables_args, log_to_wandb=False)\n",
                "    # override command line args from the tunables object\n",
                "    for k in [\"lr0\", \"clip_gradient_norm\", \"weight_decay\", \"warmup_steps\"]:\n",
                "        val = getattr(tunables, k, None)\n",
                "        if val is not None: hyp_params[k] = val\n",
                "    \n",
                "    if type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
                "        wandb_logger.experiment.config['tunables'] = dataclasses.asdict(tunables)\n",
                "\n",
                "trainer = pl.Trainer(strategy=hyp_params['strategy'],\n",
                "                  max_steps=hyp_params['iterations'],\n",
                "                  accelerator=\"gpu\",\n",
                "                  profiler=\"simple\",\n",
                "                  precision=hyp_params['precision'],\n",
                "                  gradient_clip_val=hyp_params['clip_gradient_norm'],\n",
                "                  accumulate_grad_batches=hyp_params['accumulate_grad_batches'],\n",
                "                  val_check_interval=hyp_params['validate_every_n_steps'],\n",
                "                  check_val_every_n_epoch=None,\n",
                "                  enable_checkpointing=True,\n",
                "                  logger=wandb_logger,\n",
                "                  num_nodes=int(os.environ.get('SLURM_NNODES', 1)),\n",
                "                  devices=int(os.environ.get('SLURM_NTASKS_PER_NODE', 1)),\n",
                "                  callbacks=[ckpt_callback, lr_monitor_callback])\n",
                "        \n",
                "# we initialize everything manually anyways\n",
                "with trainer.init_module(empty_init=True):\n",
                "    if args['load_from']:\n",
                "        model = task.load_model(str(args['load_from']))\n",
                "    else:\n",
                "        model_kwargs = dict(dataset=train_dss[0])\n",
                "        if tunables is not None: model_kwargs['tunables'] = tunables\n",
                "        model = parse_and_call('model', task.make_model, task_args, model_kwargs)\n",
                "\n",
                "if type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
                "    wandb_logger.experiment.config.update(hyp_params)\n",
                "    \n",
                "kwargs = {}\n",
                "if 'resume_from' in args:\n",
                "    kwargs['ckpt_path'] = args['resume_from']\n",
                "trainer.fit(model=TrainingTask(model, model_hparams=hyp_params),\n",
                "            train_dataloaders=train_loader,\n",
                "            val_dataloaders=val_loaders,\n",
                "            **kwargs)\n",
                "\n",
                "if rank_zero_only.rank == 0:\n",
                "    Path(task_name).mkdir(exist_ok=True, parents=True)\n",
                "    fname = f'{task_name}/{name}.model'\n",
                "    print('Saving:', fname)\n",
                "    model.save_model(fname)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "00406652",
            "metadata": {},
            "outputs": [],
            "source": [
                "#| hide\n",
                "import nbdev; nbdev.nbdev_export()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ffffe92",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
